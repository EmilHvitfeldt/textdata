[{"path":"/dev/CODE_OF_CONDUCT.html","id":null,"dir":"","previous_headings":"","what":"Contributor Code of Conduct","title":"Contributor Code of Conduct","text":"contributors maintainers project, pledge respect people contribute reporting issues, posting feature requests, updating documentation, submitting pull requests patches, activities. committed making participation project harassment-free experience everyone, regardless level experience, gender, gender identity expression, sexual orientation, disability, personal appearance, body size, race, ethnicity, age, religion. Examples unacceptable behavior participants include use sexual language imagery, derogatory comments personal attacks, trolling, public private harassment, insults, unprofessional conduct. Project maintainers right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct. Project maintainers follow Code Conduct may removed project team. Instances abusive, harassing, otherwise unacceptable behavior may reported opening issue contacting one project maintainers. Code Conduct adapted Contributor Covenant (https://www.contributor-covenant.org), version 1.0.0, available https://contributor-covenant.org/version/1/0/0/.","code":""},{"path":"/dev/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2018 Emil Hvitfeldt Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"/dev/articles/How-to-add-a-data-set.html","id":"guidelines-for-textdata-datasets","dir":"Articles","previous_headings":"","what":"Guidelines for textdata datasets","title":"How to add a data set","text":"datasets must license terms use clearly specified. Data vector tibble. Use word instead words column names.","code":""},{"path":"/dev/articles/How-to-add-a-data-set.html","id":"classification-datasets","dir":"Articles","previous_headings":"","what":"Classification datasets","title":"How to add a data set","text":"datasets comes testing training dataset. Let user pick one retrieve split argument similar dataset_ag_news() .","code":""},{"path":"/dev/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Emil Hvitfeldt. Author, maintainer. Julia Silge. Contributor.","code":""},{"path":"/dev/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Hvitfeldt E (2024). textdata: Download Load Various Text Datasets. R package version 0.4.5.9000, https://github.com/EmilHvitfeldt/textdata, https://emilhvitfeldt.github.io/textdata/.","code":"@Manual{,   title = {textdata: Download and Load Various Text Datasets},   author = {Emil Hvitfeldt},   year = {2024},   note = {R package version 0.4.5.9000, https://github.com/EmilHvitfeldt/textdata},   url = {https://emilhvitfeldt.github.io/textdata/}, }"},{"path":"/dev/index.html","id":"textdata-","dir":"","previous_headings":"","what":"Download and Load Various Text Datasets","title":"Download and Load Various Text Datasets","text":"goal textdata provide access text-related data sets easy access without bundling inside package. text datasets large store within R package licensed way prevents included OSS-licensed package. Instead, package provides framework download, parse, store datasets disk load needed.","code":""},{"path":"/dev/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Download and Load Various Text Datasets","text":"can install yet released version textdata CRAN : development version GitHub :","code":"install.packages(\"textdata\") # install.packages(\"remotes\") remotes::install_github(\"EmilHvitfeldt/textdata\")"},{"path":"/dev/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Download and Load Various Text Datasets","text":"first time use one functions accessing included text dataset, lexicon_afinn() dataset_sentence_polarity(), function prompt agree understand dataset’s license terms use download dataset computer.  first use, time use function like lexicon_afinn(), function load dataset disk.","code":""},{"path":"/dev/index.html","id":"included-text-datasets","dir":"","previous_headings":"","what":"Included text datasets","title":"Download and Load Various Text Datasets","text":"today, datasets included textdata : Check function’s documentation detailed information (including citations) relevant dataset.","code":""},{"path":"/dev/index.html","id":"community-guidelines","dir":"","previous_headings":"","what":"Community Guidelines","title":"Download and Load Various Text Datasets","text":"Note project released Contributor Code Conduct. contributing project, agree abide terms. Feedback, bug reports (fixes!), feature requests welcome; file issues seek support . details add new dataset package, check vignette!","code":""},{"path":"/dev/reference/cache_info.html","id":null,"dir":"Reference","previous_headings":"","what":"List folders and their sizes in cache — cache_info","title":"List folders and their sizes in cache — cache_info","text":"function return tibble name sizes folder specified directory. default textdata's default cache.","code":""},{"path":"/dev/reference/cache_info.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List folders and their sizes in cache — cache_info","text":"","code":"cache_info(dir = NULL)"},{"path":"/dev/reference/cache_info.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List folders and their sizes in cache — cache_info","text":"dir Character, path directory data stored. NULL, user_cache_dir used determine path.","code":""},{"path":"/dev/reference/cache_info.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List folders and their sizes in cache — cache_info","text":"tibble 2 variables: name Name folder size Size folder","code":""},{"path":"/dev/reference/cache_info.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"List folders and their sizes in cache — cache_info","text":"","code":"if (FALSE) { cache_info() }"},{"path":"/dev/reference/catalogue.html","id":null,"dir":"Reference","previous_headings":"","what":"Catalogue of all available data sources — catalogue","title":"Catalogue of all available data sources — catalogue","text":"Catalogue available data sources","code":""},{"path":"/dev/reference/catalogue.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Catalogue of all available data sources — catalogue","text":"","code":"catalogue"},{"path":"/dev/reference/catalogue.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Catalogue of all available data sources — catalogue","text":"object class data.frame 15 rows 8 columns.","code":""},{"path":"/dev/reference/dataset_ag_news.html","id":null,"dir":"Reference","previous_headings":"","what":"AG's News Topic Classification Dataset — dataset_ag_news","title":"AG's News Topic Classification Dataset — dataset_ag_news","text":"AG's news topic classification dataset constructed choosing 4 largest classes original corpus. class contains 30,000 training samples 1,900 testing samples. total number training samples 120,000 testing 7,600. Version 3, Updated 09/09/2015","code":""},{"path":"/dev/reference/dataset_ag_news.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"AG's News Topic Classification Dataset — dataset_ag_news","text":"","code":"dataset_ag_news(   dir = NULL,   split = c(\"train\", \"test\"),   delete = FALSE,   return_path = FALSE,   clean = FALSE,   manual_download = FALSE )"},{"path":"/dev/reference/dataset_ag_news.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"AG's News Topic Classification Dataset — dataset_ag_news","text":"http://groups.di.unipi./~gulli/AG_corpus_of_news_articles.html https://github.com/srhrshr/torchDatasets/raw/master/dbpedia_csv.tar.gz","code":""},{"path":"/dev/reference/dataset_ag_news.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"AG's News Topic Classification Dataset — dataset_ag_news","text":"dir Character, path directory data stored. NULL, user_cache_dir used determine path. split Character. Return training (\"train\") data testing (\"test\") data. Defaults \"train\". delete Logical, set TRUE delete dataset. return_path Logical, set TRUE return path dataset. clean Logical, set TRUE remove intermediate files. can greatly reduce size. Defaults FALSE. manual_download Logical, set TRUE manually downloaded file placed folder designated running function return_path = TRUE.","code":""},{"path":"/dev/reference/dataset_ag_news.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"AG's News Topic Classification Dataset — dataset_ag_news","text":"tibble 120,000 30,000 rows \"train\" \"test\"     respectively 3 variables: class Character, denoting new class title Character, title article description Character, description article","code":""},{"path":"/dev/reference/dataset_ag_news.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"AG's News Topic Classification Dataset — dataset_ag_news","text":"classes dataset World Sports Business Sci/Tech","code":""},{"path":[]},{"path":"/dev/reference/dataset_ag_news.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"AG's News Topic Classification Dataset — dataset_ag_news","text":"","code":"if (FALSE) { dataset_ag_news()  # Custom directory dataset_ag_news(dir = \"data/\")  # Deleting dataset dataset_ag_news(delete = TRUE)  # Returning filepath of data dataset_ag_news(return_path = TRUE)  # Access both training and testing dataset train <- dataset_ag_news(split = \"train\") test <- dataset_ag_news(split = \"test\") }"},{"path":"/dev/reference/dataset_dbpedia.html","id":null,"dir":"Reference","previous_headings":"","what":"DBpedia Ontology Dataset — dataset_dbpedia","title":"DBpedia Ontology Dataset — dataset_dbpedia","text":"DBpedia ontology dataset classification dataset. contains 560,000 training samples 70,000 testing samples 14 nonoverlapping classes DBpedia.","code":""},{"path":"/dev/reference/dataset_dbpedia.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"DBpedia Ontology Dataset — dataset_dbpedia","text":"","code":"dataset_dbpedia(   dir = NULL,   split = c(\"train\", \"test\"),   delete = FALSE,   return_path = FALSE,   clean = FALSE,   manual_download = FALSE )"},{"path":"/dev/reference/dataset_dbpedia.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"DBpedia Ontology Dataset — dataset_dbpedia","text":"https://papers.nips.cc/paper/5782-character-level-convolutional-networks--text-classification.pdf https://www.dbpedia.org/ https://github.com/srhrshr/torchDatasets/raw/master/dbpedia_csv.tar.gz","code":""},{"path":"/dev/reference/dataset_dbpedia.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"DBpedia Ontology Dataset — dataset_dbpedia","text":"dir Character, path directory data stored. NULL, user_cache_dir used determine path. split Character. Return training (\"train\") data testing (\"test\") data. Defaults \"train\". delete Logical, set TRUE delete dataset. return_path Logical, set TRUE return path dataset. clean Logical, set TRUE remove intermediate files. can greatly reduce size. Defaults FALSE. manual_download Logical, set TRUE manually downloaded file placed folder designated running function return_path = TRUE.","code":""},{"path":"/dev/reference/dataset_dbpedia.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"DBpedia Ontology Dataset — dataset_dbpedia","text":"tibble 560,000 70,000 rows \"train\" \"test\"     respectively 3 variables: class Character, denoting class class title Character, title article description Character, description article","code":""},{"path":"/dev/reference/dataset_dbpedia.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"DBpedia Ontology Dataset — dataset_dbpedia","text":"classes Company EducationalInstitution Artist Athlete OfficeHolder MeanOfTransportation Building NaturalPlace Village Animal Plant Album Film WrittenWork","code":""},{"path":[]},{"path":"/dev/reference/dataset_dbpedia.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"DBpedia Ontology Dataset — dataset_dbpedia","text":"","code":"if (FALSE) { dataset_dbpedia()  # Custom directory dataset_dbpedia(dir = \"data/\")  # Deleting dataset dataset_dbpedia(delete = TRUE)  # Returning filepath of data dataset_dbpedia(return_path = TRUE)  # Access both training and testing dataset train <- dataset_dbpedia(split = \"train\") test <- dataset_dbpedia(split = \"test\") }"},{"path":"/dev/reference/dataset_imdb.html","id":null,"dir":"Reference","previous_headings":"","what":"IMDB Large Movie Review Dataset — dataset_imdb","title":"IMDB Large Movie Review Dataset — dataset_imdb","text":"core dataset contains 50,000 reviews split evenly 25k train 25k test sets. overall distribution labels balanced (25k pos 25k neg).","code":""},{"path":"/dev/reference/dataset_imdb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"IMDB Large Movie Review Dataset — dataset_imdb","text":"","code":"dataset_imdb(   dir = NULL,   split = c(\"train\", \"test\"),   delete = FALSE,   return_path = FALSE,   clean = FALSE,   manual_download = FALSE )"},{"path":"/dev/reference/dataset_imdb.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"IMDB Large Movie Review Dataset — dataset_imdb","text":"http://ai.stanford.edu/~amaas/data/sentiment/","code":""},{"path":"/dev/reference/dataset_imdb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"IMDB Large Movie Review Dataset — dataset_imdb","text":"dir Character, path directory data stored. NULL, user_cache_dir used determine path. split Character. Return training (\"train\") data testing (\"test\") data. Defaults \"train\". delete Logical, set TRUE delete dataset. return_path Logical, set TRUE return path dataset. clean Logical, set TRUE remove intermediate files. can greatly reduce size. Defaults FALSE. manual_download Logical, set TRUE manually downloaded file placed folder designated running function return_path = TRUE.","code":""},{"path":"/dev/reference/dataset_imdb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"IMDB Large Movie Review Dataset — dataset_imdb","text":"tibble 25,000 rows 2 variables: Sentiment Character, denoting sentiment text Character, text review","code":""},{"path":"/dev/reference/dataset_imdb.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"IMDB Large Movie Review Dataset — dataset_imdb","text":"entire collection, 30 reviews allowed given movie reviews movie tend correlated ratings. , train test sets contain disjoint set movies, significant performance obtained memorizing movie-unique terms associated observed labels. labeled train/test sets, negative review score <= 4 10, positive review score >= 7 10. Thus reviews neutral ratings included train/test sets. unsupervised set, reviews rating included even number reviews > 5 <= 5. using dataset, please cite ACL 2011 paper InProceedings{maas-EtAl:2011:ACL-HLT2011,  author    = {Maas, Andrew L.   Daly, Raymond E.   Pham, Peter T.   Huang, Dan   Ng, Andrew Y.   Potts, Christopher},  title     = {Learning Word Vectors Sentiment Analysis},  booktitle = {Proceedings 49th Annual Meeting Association Computational Linguistics: Human Language Technologies},  month     = {June},  year      = {2011},  address   = {Portland, Oregon, USA},  publisher = {Association Computational Linguistics},  pages     = {142--150},  url       = {http://www.aclweb.org/anthology/P11-1015} }","code":""},{"path":"/dev/reference/dataset_imdb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"IMDB Large Movie Review Dataset — dataset_imdb","text":"","code":"if (FALSE) { dataset_imdb()  # Custom directory dataset_imdb(dir = \"data/\")  # Deleting dataset dataset_imdb(delete = TRUE)  # Returning filepath of data dataset_imdb(return_path = TRUE)  # Access both training and testing dataset train <- dataset_imdb(split = \"train\") test <- dataset_imdb(split = \"test\") }"},{"path":"/dev/reference/dataset_sentence_polarity.html","id":null,"dir":"Reference","previous_headings":"","what":"v1.0 sentence polarity dataset — dataset_sentence_polarity","title":"v1.0 sentence polarity dataset — dataset_sentence_polarity","text":"5331 positive 5331 negative processed sentences / snippets. Introduced Pang/Lee ACL 2005. Released July 2005.","code":""},{"path":"/dev/reference/dataset_sentence_polarity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"v1.0 sentence polarity dataset — dataset_sentence_polarity","text":"","code":"dataset_sentence_polarity(   dir = NULL,   delete = FALSE,   return_path = FALSE,   clean = FALSE,   manual_download = FALSE )"},{"path":"/dev/reference/dataset_sentence_polarity.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"v1.0 sentence polarity dataset — dataset_sentence_polarity","text":"https://www.cs.cornell.edu/people/pabo/movie-review-data/","code":""},{"path":"/dev/reference/dataset_sentence_polarity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"v1.0 sentence polarity dataset — dataset_sentence_polarity","text":"dir Character, path directory data stored. NULL, user_cache_dir used determine path. delete Logical, set TRUE delete dataset. return_path Logical, set TRUE return path dataset. clean Logical, set TRUE remove intermediate files. can greatly reduce size. Defaults FALSE. manual_download Logical, set TRUE manually downloaded file placed folder designated running function return_path = TRUE.","code":""},{"path":"/dev/reference/dataset_sentence_polarity.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"v1.0 sentence polarity dataset — dataset_sentence_polarity","text":"tibble 10,662 rows 2 variables: text Sentences snippets sentiment Indicator sentiment, \"neg\" negative \"pos\"                    positive","code":""},{"path":"/dev/reference/dataset_sentence_polarity.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"v1.0 sentence polarity dataset — dataset_sentence_polarity","text":"Citation info: data first used Bo Pang Lillian Lee, ``Seeing stars: Exploiting class relationships sentiment categorization respect rating scales.'', Proceedings ACL, 2005. InProceedings{pang05,  author    = {Bo Pang Lillian Lee},  title     = {Seeing stars: Exploiting class relationships sentiment                categorization respect rating scales},  booktitle = {Proceedings ACL},  year      = 2005  }","code":""},{"path":"/dev/reference/dataset_sentence_polarity.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"v1.0 sentence polarity dataset — dataset_sentence_polarity","text":"","code":"if (FALSE) { dataset_sentence_polarity()  # Custom directory dataset_sentence_polarity(dir = \"data/\")  # Deleting dataset dataset_sentence_polarity(delete = TRUE)  # Returning filepath of data dataset_sentence_polarity(return_path = TRUE) }"},{"path":"/dev/reference/dataset_trec.html","id":null,"dir":"Reference","previous_headings":"","what":"TREC dataset — dataset_trec","title":"TREC dataset — dataset_trec","text":"TREC dataset dataset question classification consisting open-domain, fact-based questions divided broad semantic categories. six-class (TREC-6) fifty-class (TREC-50) version. 5,452 training examples 500 test examples, TREC-50 finer-grained labels. Models evaluated based accuracy.","code":""},{"path":"/dev/reference/dataset_trec.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"TREC dataset — dataset_trec","text":"","code":"dataset_trec(   dir = NULL,   split = c(\"train\", \"test\"),   version = c(\"6\", \"50\"),   delete = FALSE,   return_path = FALSE,   clean = FALSE,   manual_download = FALSE )"},{"path":"/dev/reference/dataset_trec.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"TREC dataset — dataset_trec","text":"https://cogcomp.seas.upenn.edu/Data/QA/QC/ https://trec.nist.gov/data/qa.html","code":""},{"path":"/dev/reference/dataset_trec.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"TREC dataset — dataset_trec","text":"dir Character, path directory data stored. NULL, user_cache_dir used determine path. split Character. Return training (\"train\") data testing (\"test\") data. Defaults \"train\". version Character. Version 6(\"6\") version 50(\"50\"). Defaults \"6\". delete Logical, set TRUE delete dataset. return_path Logical, set TRUE return path dataset. clean Logical, set TRUE remove intermediate files. can greatly reduce size. Defaults FALSE. manual_download Logical, set TRUE manually downloaded file placed folder designated running function return_path = TRUE.","code":""},{"path":"/dev/reference/dataset_trec.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"TREC dataset — dataset_trec","text":"tibble 5,452 500 rows \"train\" \"test\"     respectively 2 variables: class Character, denoting class text Character, question text","code":""},{"path":"/dev/reference/dataset_trec.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"TREC dataset — dataset_trec","text":"classes TREC-6 ABBR - Abbreviation DESC - Description abstract concepts ENTY - Entities HUM - Human beings LOC - Locations NYM - Numeric values classes TREC-50 can found https://cogcomp.seas.upenn.edu/Data/QA/QC/definition.html.","code":""},{"path":[]},{"path":"/dev/reference/dataset_trec.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"TREC dataset — dataset_trec","text":"","code":"if (FALSE) { dataset_trec()  # Custom directory dataset_trec(dir = \"data/\")  # Deleting dataset dataset_trec(delete = TRUE)  # Returning filepath of data dataset_trec(return_path = TRUE)  # Access both training and testing dataset train_6 <- dataset_trec(split = \"train\") test_6 <- dataset_trec(split = \"test\")  train_50 <- dataset_trec(split = \"train\", version = \"50\") test_50 <- dataset_trec(split = \"test\", version = \"50\") }"},{"path":"/dev/reference/embedding_glove.html","id":null,"dir":"Reference","previous_headings":"","what":"Global Vectors for Word Representation — embedding_glove","title":"Global Vectors for Word Representation — embedding_glove","text":"GloVe pre-trained word vectors provide word embeddings created using varying numbers tokens.","code":""},{"path":"/dev/reference/embedding_glove.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Global Vectors for Word Representation — embedding_glove","text":"","code":"embedding_glove6b(   dir = NULL,   dimensions = c(50, 100, 200, 300),   delete = FALSE,   return_path = FALSE,   clean = FALSE,   manual_download = FALSE )  embedding_glove27b(   dir = NULL,   dimensions = c(25, 50, 100, 200),   delete = FALSE,   return_path = FALSE,   clean = FALSE,   manual_download = FALSE )  embedding_glove42b(   dir = NULL,   delete = FALSE,   return_path = FALSE,   clean = FALSE,   manual_download = FALSE )  embedding_glove840b(   dir = NULL,   delete = FALSE,   return_path = FALSE,   clean = FALSE,   manual_download = FALSE )"},{"path":"/dev/reference/embedding_glove.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Global Vectors for Word Representation — embedding_glove","text":"https://nlp.stanford.edu/projects/glove/","code":""},{"path":"/dev/reference/embedding_glove.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Global Vectors for Word Representation — embedding_glove","text":"dir Character, path directory data stored. NULL, user_cache_dir used determine path. dimensions number indicating number vectors include. One 50, 100, 200, 300 glove6b, one 25, 50, 100, 200 glove27b. delete Logical, set TRUE delete dataset. return_path Logical, set TRUE return path dataset. clean Logical, set TRUE remove intermediate files. can greatly reduce size. Defaults FALSE. manual_download Logical, set TRUE manually downloaded file placed folder designated running function return_path = TRUE.","code":""},{"path":"/dev/reference/embedding_glove.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Global Vectors for Word Representation — embedding_glove","text":"tibble 400k, 1.9m, 2.2m, 1.2m rows (one row unique   token vocabulary) following variables: token individual token (usually word) d1, d2, etc embeddings token.","code":""},{"path":"/dev/reference/embedding_glove.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Global Vectors for Word Representation — embedding_glove","text":"Citation info: InProceedings{pennington2014glove,  author     = {Jeffrey Pennington Richard Socher Christopher D.                 Manning},  title      = {GloVe: Global Vectors Word Representation},  booktitle  = {Empirical Methods Natural Language Processing (EMNLP)},  year       = 2014  pages      = {1532-1543}  url        = {http://www.aclweb.org/anthology/D14-1162}  }","code":""},{"path":"/dev/reference/embedding_glove.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Global Vectors for Word Representation — embedding_glove","text":"Jeffrey Pennington, Richard Socher, Christopher D. Manning.   2014. GloVe: Global Vectors Word Representation.","code":""},{"path":"/dev/reference/embedding_glove.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Global Vectors for Word Representation — embedding_glove","text":"","code":"if (FALSE) { embedding_glove6b(dimensions = 50)  # Custom directory embedding_glove42b(dir = \"data/\")  # Deleting dataset embedding_glove6b(delete = TRUE, dimensions = 300)  # Returning filepath of data embedding_glove840b(return_path = TRUE) }"},{"path":"/dev/reference/lexicon_afinn.html","id":null,"dir":"Reference","previous_headings":"","what":"AFINN-111 dataset — lexicon_afinn","title":"AFINN-111 dataset — lexicon_afinn","text":"AFINN lexicon English words rated valence integer minus five (negative) plus five (positive). words manually labeled Finn Årup Nielsen 2009-2011.","code":""},{"path":"/dev/reference/lexicon_afinn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"AFINN-111 dataset — lexicon_afinn","text":"","code":"lexicon_afinn(   dir = NULL,   delete = FALSE,   return_path = FALSE,   clean = FALSE,   manual_download = FALSE )"},{"path":"/dev/reference/lexicon_afinn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"AFINN-111 dataset — lexicon_afinn","text":"dir Character, path directory data stored. NULL, user_cache_dir used determine path. delete Logical, set TRUE delete dataset. return_path Logical, set TRUE return path dataset. clean Logical, set TRUE remove intermediate files. can greatly reduce size. Defaults FALSE. manual_download Logical, set TRUE manually downloaded file placed folder designated running function return_path = TRUE.","code":""},{"path":"/dev/reference/lexicon_afinn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"AFINN-111 dataset — lexicon_afinn","text":"tibble 2,477 rows 2 variables: word English word score Indicator sentiment: integer -5 +5","code":""},{"path":"/dev/reference/lexicon_afinn.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"AFINN-111 dataset — lexicon_afinn","text":"dataset newest version 2477 words phrases. Citation info: dataset published Finn Ärup Nielsen (2011), ``new Evaluation word list sentiment analysis microblogs'', Proceedings ESWC2011 Workshop 'Making Sense Microposts': Big things come small packages (2011) 93-98. article{nielsen11,  author    = {Finn Äruprup Nielsen},  title     = {new Evaluation word list sentiment analysis microblogs},  journal   = {CoRR},  volume    = {abs/1103.2903},  year      = {2011},  url       = {http://arxiv.org/abs/1103.2903},  archivePrefix = {arXiv},  eprint    = {1103.2903},  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1103-2903},  bibsource = {dblp computer science bibliography, https://dblp.org}  }","code":""},{"path":[]},{"path":"/dev/reference/lexicon_afinn.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"AFINN-111 dataset — lexicon_afinn","text":"","code":"if (FALSE) { lexicon_afinn()  # Custom directory lexicon_afinn(dir = \"data/\")  # Deleting dataset lexicon_afinn(delete = TRUE)  # Returning filepath of data lexicon_afinn(return_path = TRUE) }"},{"path":"/dev/reference/lexicon_bing.html","id":null,"dir":"Reference","previous_headings":"","what":"Bing sentiment lexicon — lexicon_bing","title":"Bing sentiment lexicon — lexicon_bing","text":"General purpose English sentiment lexicon categorizes words binary fashion, either positive negative","code":""},{"path":"/dev/reference/lexicon_bing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bing sentiment lexicon — lexicon_bing","text":"","code":"lexicon_bing(   dir = NULL,   delete = FALSE,   return_path = FALSE,   clean = FALSE,   manual_download = FALSE )"},{"path":"/dev/reference/lexicon_bing.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Bing sentiment lexicon — lexicon_bing","text":"https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html","code":""},{"path":"/dev/reference/lexicon_bing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bing sentiment lexicon — lexicon_bing","text":"dir Character, path directory data stored. NULL, user_cache_dir used determine path. delete Logical, set TRUE delete dataset. return_path Logical, set TRUE return path dataset. clean Logical, set TRUE remove intermediate files. can greatly reduce size. Defaults FALSE. manual_download Logical, set TRUE manually downloaded file placed folder designated running function return_path = TRUE.","code":""},{"path":"/dev/reference/lexicon_bing.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bing sentiment lexicon — lexicon_bing","text":"tibble 6,787 rows 2 variables: word English word sentiment Indicator sentiment: \"negative\" \"positive\"","code":""},{"path":"/dev/reference/lexicon_bing.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bing sentiment lexicon — lexicon_bing","text":"Citation info: dataset first published Minqing Hu Bing Liu, ``Mining summarizing customer reviews.'', Proceedings ACM SIGKDD International Conference Knowledge Discovery & Data Mining (KDD-2004), 2004. inproceedings{Hu04,  author    = {Hu, Minqing Liu, Bing},  title     = {Mining Summarizing Customer Reviews},  booktitle = {Proceedings Tenth ACM SIGKDD International Conference               Knowledge Discovery Data Mining},  series    = {KDD '04},  year      = {2004},  isbn      = {1-58113-888-1},  location  = {Seattle, WA, USA},  pages     = {168--177},  numpages  = {10},  url       = {http://doi.acm.org/10.1145/1014052.1014073},  doi       = {10.1145/1014052.1014073},  acmid     = {1014073},  publisher = {ACM},  address   = {New York, NY, USA},  keywords  = {reviews, sentiment classification, summarization, text mining},  }","code":""},{"path":[]},{"path":"/dev/reference/lexicon_bing.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bing sentiment lexicon — lexicon_bing","text":"","code":"if (FALSE) { lexicon_bing()  # Custom directory lexicon_bing(dir = \"data/\")  # Deleting dataset lexicon_bing(delete = TRUE)  # Returning filepath of data lexicon_bing(return_path = TRUE) }"},{"path":"/dev/reference/lexicon_loughran.html","id":null,"dir":"Reference","previous_headings":"","what":"Loughran-McDonald sentiment lexicon — lexicon_loughran","title":"Loughran-McDonald sentiment lexicon — lexicon_loughran","text":"English sentiment lexicon created use financial documents. lexicon labels words six possible sentiments important financial contexts: \"negative\", \"positive\", \"litigious\", \"uncertainty\", \"constraining\", \"superfluous\".","code":""},{"path":"/dev/reference/lexicon_loughran.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Loughran-McDonald sentiment lexicon — lexicon_loughran","text":"","code":"lexicon_loughran(   dir = NULL,   delete = FALSE,   return_path = FALSE,   clean = FALSE,   manual_download = FALSE )"},{"path":"/dev/reference/lexicon_loughran.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Loughran-McDonald sentiment lexicon — lexicon_loughran","text":"https://sraf.nd.edu/loughranmcdonald-master-dictionary/","code":""},{"path":"/dev/reference/lexicon_loughran.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Loughran-McDonald sentiment lexicon — lexicon_loughran","text":"dir Character, path directory data stored. NULL, user_cache_dir used determine path. delete Logical, set TRUE delete dataset. return_path Logical, set TRUE return path dataset. clean Logical, set TRUE remove intermediate files. can greatly reduce size. Defaults FALSE. manual_download Logical, set TRUE manually downloaded file placed folder designated running function return_path = TRUE.","code":""},{"path":"/dev/reference/lexicon_loughran.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Loughran-McDonald sentiment lexicon — lexicon_loughran","text":"tibble 4,150 rows 2 variables: word English word sentiment Indicator sentiment: \"negative\", \"positive\",   \"litigious\", \"uncertainty\", \"constraining\", \"superfluous\"","code":""},{"path":"/dev/reference/lexicon_loughran.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Loughran-McDonald sentiment lexicon — lexicon_loughran","text":"Citation info: dataset published Loughran, T. McDonald, B. (2011), ``Liability Liability? Textual Analysis, Dictionaries, 10-Ks.'' Journal Finance, 66: 35-65. article{loughran11,  author  = {Loughran, Tim McDonald, Bill},  title   = {Liability Liability? Textual Analysis, Dictionaries, 10-Ks},  journal = {Journal Finance},  volume  = {66},  number  = {1},  pages   = {35-65},  doi     = {10.1111/j.1540-6261.2010.01625.x},  url     = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1540-6261.2010.01625.x},  eprint  = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1540-6261.2010.01625.x},  year    = {2011}  }","code":""},{"path":[]},{"path":"/dev/reference/lexicon_loughran.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Loughran-McDonald sentiment lexicon — lexicon_loughran","text":"","code":"if (FALSE) { lexicon_loughran()  # Custom directory lexicon_loughran(dir = \"data/\")  # Deleting dataset lexicon_loughran(delete = TRUE)  # Returning filepath of data lexicon_loughran(return_path = TRUE) }"},{"path":"/dev/reference/lexicon_nrc.html","id":null,"dir":"Reference","previous_headings":"","what":"NRC word-emotion association lexicon — lexicon_nrc","title":"NRC word-emotion association lexicon — lexicon_nrc","text":"General purpose English sentiment/emotion lexicon. lexicon labels words six possible sentiments emotions: \"negative\", \"positive\", \"anger\", \"anticipation\", \"disgust\", \"fear\", \"joy\", \"sadness\", \"surprise\", \"trust\". annotations manually done Amazon's Mechanical Turk.","code":""},{"path":"/dev/reference/lexicon_nrc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"NRC word-emotion association lexicon — lexicon_nrc","text":"","code":"lexicon_nrc(   dir = NULL,   delete = FALSE,   return_path = FALSE,   clean = FALSE,   manual_download = FALSE )"},{"path":"/dev/reference/lexicon_nrc.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"NRC word-emotion association lexicon — lexicon_nrc","text":"http://saifmohammad.com/WebPages/lexicons.html","code":""},{"path":"/dev/reference/lexicon_nrc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"NRC word-emotion association lexicon — lexicon_nrc","text":"dir Character, path directory data stored. NULL, user_cache_dir used determine path. delete Logical, set TRUE delete dataset. return_path Logical, set TRUE return path dataset. clean Logical, set TRUE remove intermediate files. can greatly reduce size. Defaults FALSE. manual_download Logical, set TRUE manually downloaded file placed folder designated running function return_path = TRUE.","code":""},{"path":"/dev/reference/lexicon_nrc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"NRC word-emotion association lexicon — lexicon_nrc","text":"tibble 13,901 rows 2 variables: word English word sentiment Indicator sentiment emotion: \"negative\",   \"positive\", \"anger\", \"anticipation\", \"disgust\", \"fear\", \"joy\", \"sadness\",   \"surprise\", \"trust\"","code":""},{"path":"/dev/reference/lexicon_nrc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"NRC word-emotion association lexicon — lexicon_nrc","text":"License required commercial use. Please contact Saif M. Mohammad (saif.mohammad@nrc-cnrc.gc.ca). Citation info: dataset published Saif Mohammad Peter Turney. (2013), ``Crowdsourcing Word-Emotion Association Lexicon.'' Computational Intelligence, 29(3): 436-465. article{mohammad13,  author = {Mohammad, Saif M. Turney, Peter D.},  title = {CROWDSOURCING WORD–EMOTION ASSOCIATION LEXICON},  journal = {Computational Intelligence},  volume = {29},  number = {3},  pages = {436-465},  doi = {10.1111/j.1467-8640.2012.00460.x},  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8640.2012.00460.x},  eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-8640.2012.00460.x},  year = {2013}  }","code":""},{"path":[]},{"path":"/dev/reference/lexicon_nrc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"NRC word-emotion association lexicon — lexicon_nrc","text":"","code":"if (FALSE) { lexicon_nrc()  # Custom directory lexicon_nrc(dir = \"data/\")  # Deleting dataset lexicon_nrc(delete = TRUE)  # Returning filepath of data lexicon_nrc(return_path = TRUE) }"},{"path":"/dev/reference/lexicon_nrc_eil.html","id":null,"dir":"Reference","previous_headings":"","what":"NRC Emotion Intensity Lexicon (aka Affect Intensity Lexicon) v0.5 — lexicon_nrc_eil","title":"NRC Emotion Intensity Lexicon (aka Affect Intensity Lexicon) v0.5 — lexicon_nrc_eil","text":"General purpose English sentiment/emotion lexicon. NRC Affect Intensity Lexicon list English words associations four basic emotions (anger, fear, sadness, joy).","code":""},{"path":"/dev/reference/lexicon_nrc_eil.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"NRC Emotion Intensity Lexicon (aka Affect Intensity Lexicon) v0.5 — lexicon_nrc_eil","text":"","code":"lexicon_nrc_eil(   dir = NULL,   delete = FALSE,   return_path = FALSE,   clean = FALSE,   manual_download = FALSE )"},{"path":"/dev/reference/lexicon_nrc_eil.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"NRC Emotion Intensity Lexicon (aka Affect Intensity Lexicon) v0.5 — lexicon_nrc_eil","text":"https://saifmohammad.com/WebPages/AffectIntensity.htm","code":""},{"path":"/dev/reference/lexicon_nrc_eil.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"NRC Emotion Intensity Lexicon (aka Affect Intensity Lexicon) v0.5 — lexicon_nrc_eil","text":"dir Character, path directory data stored. NULL, user_cache_dir used determine path. delete Logical, set TRUE delete dataset. return_path Logical, set TRUE return path dataset. clean Logical, set TRUE remove intermediate files. can greatly reduce size. Defaults FALSE. manual_download Logical, set TRUE manually downloaded file placed folder designated running function return_path = TRUE.","code":""},{"path":"/dev/reference/lexicon_nrc_eil.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"NRC Emotion Intensity Lexicon (aka Affect Intensity Lexicon) v0.5 — lexicon_nrc_eil","text":"tibble 5.814 rows 3 variables: term English word score Value 0 1 AffectDimension Indicator sentiment emotion: (\"anger\",                          \"fear\", \"sadness\", \"joy\")","code":""},{"path":"/dev/reference/lexicon_nrc_eil.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"NRC Emotion Intensity Lexicon (aka Affect Intensity Lexicon) v0.5 — lexicon_nrc_eil","text":"given word emotion X, scores range 0 1. score 1 means word conveys highest amount emotion X.  score 0 means word conveys lowest amount emotion X. License required commercial use. Please contact Saif M. Mohammad (saif.mohammad@nrc-cnrc.gc.ca). Citation info: Details lexicon paper. Word Affect Intensities. Saif M. Mohammad. Proceedings 11th Edition Language Resources Evaluation Conference (LREC-2018), May 2018, Miyazaki, Japan. inproceedings{LREC18-AIL,  author = {Mohammad, Saif M.},  title = {Word Affect Intensities},  booktitle = {Proceedings 11th Edition Language Resources Evaluation Conference (LREC-2018)},  year = {2018},  address={Miyazaki, Japan}  }","code":""},{"path":[]},{"path":"/dev/reference/lexicon_nrc_eil.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"NRC Emotion Intensity Lexicon (aka Affect Intensity Lexicon) v0.5 — lexicon_nrc_eil","text":"","code":"if (FALSE) { lexicon_nrc_eil()  # Custom directory lexicon_nrc_eil(dir = \"data/\")  # Deleting dataset lexicon_nrc_eil(delete = TRUE)  # Returning filepath of data lexicon_nrc_eil(return_path = TRUE) }"},{"path":"/dev/reference/lexicon_nrc_vad.html","id":null,"dir":"Reference","previous_headings":"","what":"The NRC Valence, Arousal, and Dominance Lexicon — lexicon_nrc_vad","title":"The NRC Valence, Arousal, and Dominance Lexicon — lexicon_nrc_vad","text":"NRC Valence, Arousal, Dominance (VAD) Lexicon includes list 20,000 English words valence, arousal, dominance scores. given word dimension (V//D), scores range 0 (lowest V//D) 1 (highest V//D). lexicon fine-grained real- valued scores created manual annotation using best--worst scaling. lexicon markedly larger existing VAD lexicons. also show ratings obtained substantially reliable existing lexicons.","code":""},{"path":"/dev/reference/lexicon_nrc_vad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The NRC Valence, Arousal, and Dominance Lexicon — lexicon_nrc_vad","text":"","code":"lexicon_nrc_vad(   dir = NULL,   delete = FALSE,   return_path = FALSE,   clean = FALSE,   manual_download = FALSE )"},{"path":"/dev/reference/lexicon_nrc_vad.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"The NRC Valence, Arousal, and Dominance Lexicon — lexicon_nrc_vad","text":"https://saifmohammad.com/WebPages/nrc-vad.html","code":""},{"path":"/dev/reference/lexicon_nrc_vad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The NRC Valence, Arousal, and Dominance Lexicon — lexicon_nrc_vad","text":"dir Character, path directory data stored. NULL, user_cache_dir used determine path. delete Logical, set TRUE delete dataset. return_path Logical, set TRUE return path dataset. clean Logical, set TRUE remove intermediate files. can greatly reduce size. Defaults FALSE. manual_download Logical, set TRUE manually downloaded file placed folder designated running function return_path = TRUE.","code":""},{"path":"/dev/reference/lexicon_nrc_vad.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"The NRC Valence, Arousal, and Dominance Lexicon — lexicon_nrc_vad","text":"tibble 20.007 rows 4 variables: word English word Valence valence score word Arousal arousal score word Dominance dominance score word","code":""},{"path":"/dev/reference/lexicon_nrc_vad.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The NRC Valence, Arousal, and Dominance Lexicon — lexicon_nrc_vad","text":"License required commercial use. Please contact Saif M. Mohammad (saif.mohammad@nrc-cnrc.gc.ca). Citation info: Details NRC VAD Lexicon available paper: Obtaining Reliable Human Ratings Valence, Arousal, Dominance 20,000 English Words.  Saif M. Mohammad. Proceedings 56th Annual Meeting Association Computational Linguistics, Melbourne, Australia, July 2018. inproceedings{vad-acl2018,  title={Obtaining Reliable Human Ratings Valence, Arousal, Dominance 20,000 English Words},  author={Mohammad, Saif M.},  booktitle={Proceedings Annual Conference Association Computational Linguistics (ACL)},  year={2018},  address={Melbourne, Australia}  }","code":""},{"path":[]},{"path":"/dev/reference/lexicon_nrc_vad.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"The NRC Valence, Arousal, and Dominance Lexicon — lexicon_nrc_vad","text":"","code":"if (FALSE) { lexicon_nrc_vad()  # Custom directory lexicon_nrc_vad(dir = \"data/\")  # Deleting dataset lexicon_nrc_vad(delete = TRUE)  # Returning filepath of data lexicon_nrc_vad(return_path = TRUE) }"},{"path":"/dev/reference/load_dataset.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal Functions — load_dataset","title":"Internal Functions — load_dataset","text":"used directly users.","code":""},{"path":"/dev/reference/load_dataset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal Functions — load_dataset","text":"","code":"load_dataset(   data_name,   name,   dir,   delete,   return_path,   clean,   clean_manual = NULL,   manual_download )"},{"path":"/dev/reference/textdata-package.html","id":null,"dir":"Reference","previous_headings":"","what":"textdata: Download and Load Various Text Datasets — textdata-package","title":"textdata: Download and Load Various Text Datasets — textdata-package","text":"Provides framework download, parse, store text datasets disk load needed. Includes various sentiment lexicons labeled text data sets classification analysis.","code":""},{"path":[]},{"path":"/dev/reference/textdata-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"textdata: Download and Load Various Text Datasets — textdata-package","text":"Maintainer: Emil Hvitfeldt emilhhvitfeldt@gmail.com (ORCID) contributors: Julia Silge julia.silge@gmail.com (ORCID) [contributor]","code":""},{"path":[]},{"path":"/dev/news/index.html","id":"textdata-045","dir":"Changelog","previous_headings":"","what":"textdata 0.4.5","title":"textdata 0.4.5","text":"CRAN release: 2024-05-28 Fixed bug lexicon_nrc_vad() didn’t column names. (#53)","code":""},{"path":"/dev/news/index.html","id":"textdata-044","dir":"Changelog","previous_headings":"","what":"textdata 0.4.4","title":"textdata 0.4.4","text":"CRAN release: 2022-09-02 Update path correctly path source NRC lexicon.","code":""},{"path":"/dev/news/index.html","id":"textdata-043","dir":"Changelog","previous_headings":"","what":"textdata 0.4.3","title":"textdata 0.4.3","text":"CRAN release: 2022-08-15 Fixed documentation HTML5 friendly.","code":""},{"path":"/dev/news/index.html","id":"textdata-042","dir":"Changelog","previous_headings":"","what":"textdata 0.4.2","title":"textdata 0.4.2","text":"CRAN release: 2022-05-02 cache_info() function added allow quick overview cacheing size. Update download url lexicon_nrc().","code":""},{"path":"/dev/news/index.html","id":"textdata-041","dir":"Changelog","previous_headings":"","what":"textdata 0.4.1","title":"textdata 0.4.1","text":"CRAN release: 2020-05-04","code":""},{"path":"/dev/news/index.html","id":"textdata-040","dir":"Changelog","previous_headings":"","what":"textdata 0.4.0","title":"textdata 0.4.0","text":"CRAN release: 2020-03-06 embedding_glove6b(), embedding_glove27b(), embedding_glove42b(), embedding_glove840b() added give access Stanford NLP Global Vectors Word Representations pre-trained word vectors (@jonthegeek, #26). manual_download argument added functions allow user manual place file download right place.","code":""},{"path":"/dev/news/index.html","id":"textdata-030","dir":"Changelog","previous_headings":"","what":"textdata 0.3.0","title":"textdata 0.3.0","text":"CRAN release: 2019-08-28 lexicon_nrc_eil() added give access NRC Emotion Intensity Lexicon (aka Affect Intensity Lexicon) v0.5. lexicon_nrc_vad() added give access NRC Valence, Arousal, Dominance Lexicon. argument clean added functions allow deletion intermediate files. optional information prompt implemented. turned default turned original authors request. dataset_nrc() got improved url faster reliable downloads.","code":""},{"path":"/dev/news/index.html","id":"textdata-020","dir":"Changelog","previous_headings":"","what":"textdata 0.2.0","title":"textdata 0.2.0","text":"CRAN release: 2019-07-22 dataset_imdb() added give access IMDb Large Movie Review Dataset. dataset_trec() added give access TREC-6 TREC-50 classification datasets. dataset_dbpedia() added give access DBpedia Ontology classification dataset. dataset_ag_news() added give access AG’s News Topic classification dataset. Functions now notify user download mechanism used download data. http/https etc. (#12). lexicon_nrc() added give access NRC Emotion lexicon (@juliasilge, #11).","code":""},{"path":"/dev/news/index.html","id":"textdata-010","dir":"Changelog","previous_headings":"","what":"textdata 0.1.0","title":"textdata 0.1.0","text":"CRAN release: 2019-06-12","code":""}]
